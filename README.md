# Modelo de Probabilidade de Default (PD) 

## ğŸ“Œ DescriÃ§Ã£o do Projeto  

Este repositÃ³rio contÃ©m o desenvolvimento de um **modelo de Probabilidade de Default (PD)** aplicado sobre uma base fictÃ­cia de clientes, transaÃ§Ãµes e histÃ³rico de inadimplÃªncia.  

O fluxo foi estruturado para refletir as **boas prÃ¡ticas de modelagem de risco de crÃ©dito**, abordando os processos de ***feature engineering*, consolidaÃ§Ã£o da ABT (Analytical Base Table), seleÃ§Ã£o de variÃ¡veis e a modelagem em si**.  

- **Desenvolvimento do Projeto:** [Projeto PD](notebook/case_PD.ipynb)  

---

## Estrutura do projeto

.
â”œâ”€â”€ data/                   # Dados brutos e processados 
â”‚   â”œâ”€â”€ raw/                # Bases originais (ex: clientes_case.csv, transacoes_case.csv)
â”‚   â””â”€â”€ processed/          # ABTs finais prontas para modelagem        
â”œâ”€â”€ notebooks/              # Desenvolvimento do modelo. ContÃ©m anÃ¡lises exploratÃ³rias e
â”‚   â””â”€â”€ case_PD.ipynb       # modelagem
â”‚
â”œâ”€â”€ pipeline/               # Scripts modulares para execuÃ§Ã£o do pipeline. 
â”‚   â”œâ”€â”€ feature_clientes.py
â”‚   â”œâ”€â”€ feature_transacoes.py
â”‚   â”œâ”€â”€ feature_inadimplencia.py
â”‚   â”œâ”€â”€ criar_abt.py      # ConsolidaÃ§Ã£o da ABT
â”‚   â””â”€â”€ utils.py            # FunÃ§Ãµes auxiliares reutilizÃ¡veis
â”‚
â”œâ”€â”€ reports/                # SaÃ­das analÃ­ticas
â”‚   â”œâ”€â”€ resultados.pdf      # RelatÃ³rio consolidado
â”‚   â”œâ”€â”€ figures/            # GrÃ¡ficos e imagens finais
â”‚   â””â”€â”€ logs/               # Logs de execuÃ§Ã£o
â”‚
â”œâ”€â”€ tests/                  # Testes unitÃ¡rios e validaÃ§Ã£o do pipeline
â”‚   â””â”€â”€ test_utils.py
â”‚
â”œâ”€â”€ requirements.txt        # DependÃªncias do projeto
â”œâ”€â”€ .gitignore              # Arquivos/pastas ignorados no versionamento
â””â”€â”€ README.md               # DocumentaÃ§Ã£o principal


---

## ğŸ¯ Entendimento do NegÃ³cio  

O objetivo Ã© estimar a **probabilidade de inadimplÃªncia (default)** em determinado horizonte de tempo, considerando o perfil cadastral, histÃ³rico transacional e comportamento prÃ©vio dos clientes.  

**DEFAULT DA CARTEIRA DE CLIENTES: 10%**

**KPIs de avaliaÃ§Ã£o:**  
- AUC (ROC-AUC) 
- KS (Kolmogorov-Smirnov)  
- *Precision* e *recall*

---

## âš™ï¸ PrÃ©-Processamento dos Dados  

1. PadronizaÃ§Ã£o e consistÃªncia de colunas.  
2. ConstruÃ§Ã£o da **ABT (Analytical Base Table)** com janelas de observaÃ§Ã£o e performance (`mes_safra`).  
   - Garantido que apenas informaÃ§Ãµes **de M-1** estejam disponÃ­veis em M, evitando vazamento de informaÃ§Ãµes de safras ainda nÃ£o maturadas.  
3. Tratamento de valores faltantes e variÃ¡veis categÃ³ricas.  

---

## ğŸ› ï¸ SeleÃ§Ã£o de VariÃ¡veis  

Antes da modelagem, foi realizada uma etapa de prÃ©-seleÃ§Ã£o:  

- **CorrelaÃ§Ã£o**: remoÃ§Ã£o de variÃ¡veis com correlaÃ§Ã£o > 0.8.  
- **Information Value (IV)**: exclusÃ£o de variÃ¡veis com baixo poder discriminatÃ³rio.  

---

## ğŸ¤– Modelagem  

Modelos avaliados:  
- **Decision Trees** â€“ baseline com regras simples de classificaÃ§Ã£o.  
- **RegressÃ£o LogÃ­stica** â€“ referÃªncia estatÃ­stica e interpretabilidade.  
- **CatBoost** â€“ algoritmo de *gradient boosting* para maior performance esperada.  

### ğŸ” EstratÃ©gia de Treino  
- DivisÃ£o treino/validaÃ§Ã£o baseada em `mes_safra`.  
- **RandomizedSearchCV** para ajuste de hiperparÃ¢metros.  

### ğŸ“Š Resultados  


---

## ğŸ“ˆ ConclusÃ£o EstratÃ©gica  

- A abordagem confirmou que **variÃ¡veis transacionais e de recÃªncia** tÃªm maior relevÃ¢ncia na explicaÃ§Ã£o do default.  
- O processo de **seleÃ§Ã£o de variÃ¡veis (correlaÃ§Ã£o + IV)** reduziu dimensionalidade e aumentou a robustez do modelo.  
- O desbalanceamento se mostrou a maior questÃ£o a ser resolvida

---

## ğŸš€ PrÃ³ximos Passos  

1. **Feature Engineering avanÃ§ada** â€“ incluir novas variÃ¡veis derivadas, interaÃ§Ãµes e efeitos de sazonalidade.  
2. **AnÃ¡lise de Lifting** â€“ avaliaÃ§Ã£o da capacidade de segmentaÃ§Ã£o dos clientes em decisores de negÃ³cio.  
3. **Balanceamento de classes** â€“ investigar tÃ©cnicas de oversampling/undersampling.  
4. **Deployment** â€“ disponibilizar o modelo como API ou batch processÃ¡vel.  
5. **Versionamento** â€“ acoplar rastreamento de experimentos (ex: MLflow).  
